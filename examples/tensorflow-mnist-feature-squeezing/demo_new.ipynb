{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow MNIST Classifier demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">⚠️ **Warning:** Some of the attacks in this demo, _deepfool_ and _CW_ in particular, are computationally expensive and will take a very long to complete if run using the CPUs found in a typical personal computer.\n",
    "> For this reason, it is highly recommended that you run these demos on a CUDA-compatible GPU.\n",
    "\n",
    "This notebook contains an end-to-end demostration of Dioptra that can be run on any modern laptop.\n",
    "Please see the [example README](README.md) for instructions on how to prepare your environment for running this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we import the necessary Python modules and ensure the proper environment variables are set so that all the code blocks will work as expected,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import packages from the Python standard library\n",
    "import importlib.util\n",
    "import os\n",
    "import sys\n",
    "import pprint\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def register_python_source_file(module_name: str, filepath: Path) -> None:\n",
    "    \"\"\"Import a source file directly.\n",
    "\n",
    "    Args:\n",
    "        module_name: The module name to associate with the imported source file.\n",
    "        filepath: The path to the source file.\n",
    "\n",
    "    Notes:\n",
    "        Adapted from the following implementation in the Python documentation:\n",
    "        https://docs.python.org/3/library/importlib.html#importing-a-source-file-directly\n",
    "    \"\"\"\n",
    "    spec = importlib.util.spec_from_file_location(module_name, str(filepath))\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    sys.modules[module_name] = module\n",
    "    spec.loader.exec_module(module)\n",
    "\n",
    "\n",
    "# Filter out warning messages\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Experiment name\n",
    "EXPERIMENT_NAME = \"jminiter_feature_squeezing\"\n",
    "\n",
    "# Default address for accessing the RESTful API service\n",
    "RESTAPI_ADDRESS = \"http://localhost:80\"\n",
    "\n",
    "# Set DIOPTRA_RESTAPI_URI variable if not defined, used to connect to RESTful API service\n",
    "if os.getenv(\"DIOPTRA_RESTAPI_URI\") is None:\n",
    "    os.environ[\"DIOPTRA_RESTAPI_URI\"] = RESTAPI_ADDRESS\n",
    "\n",
    "# Default address for accessing the MLFlow Tracking server\n",
    "MLFLOW_TRACKING_URI = \"http://localhost:35000\"\n",
    "\n",
    "# Set MLFLOW_TRACKING_URI variable, used to connect to MLFlow Tracking service\n",
    "if os.getenv(\"MLFLOW_TRACKING_URI\") is None:\n",
    "    os.environ[\"MLFLOW_TRACKING_URI\"] = MLFLOW_TRACKING_URI\n",
    "\n",
    "# Path to workflows archive\n",
    "WORKFLOWS_TAR_GZ = Path(\"workflows.tar.gz\")\n",
    "\n",
    "# Register the examples/scripts directory as a Python module\n",
    "register_python_source_file(\"scripts\", Path(\"..\", \"scripts\", \"__init__.py\"))\n",
    "\n",
    "from scripts.client import DioptraClient\n",
    "from scripts.utils import make_tar\n",
    "\n",
    "# Import third-party Python packages\n",
    "import numpy as np\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Create random number generator\n",
    "rng = np.random.default_rng(54399264723942495723666216079516778448)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mnist_model = \"mnist_le_net\" \n",
    "mnist_shallow = \"mnist_shallow_net\"\n",
    "model_id = 5\n",
    "model_id_shallow = 3\n",
    "mnist_dataset = \"/dioptra/data/Mnist\"\n",
    "mlflow_queue = \"tensorflow_gpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtained a copy of the MNIST dataset when we ran `download_data.py` script. If you have not done so already, see [How to Obtain Common Datasets](https://pages.nist.gov/dioptra/getting-started/acquiring-datasets.html).\n",
    "The training and testing images for the MNIST dataset are stored within the `/dioptra/data/Mnist` directory as PNG files that are organized into the following folder structure,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Mnist\n",
    "    ├── testing\n",
    "    │   ├── 0\n",
    "    │   ├── 1\n",
    "    │   ├── 2\n",
    "    │   ├── 3\n",
    "    │   ├── 4\n",
    "    │   ├── 5\n",
    "    │   ├── 6\n",
    "    │   ├── 7\n",
    "    │   ├── 8\n",
    "    │   └── 9\n",
    "    └── training\n",
    "        ├── 0\n",
    "        ├── 1\n",
    "        ├── 2\n",
    "        ├── 3\n",
    "        ├── 4\n",
    "        ├── 5\n",
    "        ├── 6\n",
    "        ├── 7\n",
    "        ├── 8\n",
    "        └── 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subfolders under `training/` and `testing/` are the classification labels for the images in the dataset.\n",
    "This folder structure is a standardized way to encode the label information and many libraries can make use of it, including the Tensorflow library that we are using for this particular demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit and run jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entrypoints that we will be running in this example are implemented in the Python source files under `src/` and the `src/MLproject` file.\n",
    "To run these entrypoints within Dioptra's architecture, we need to package those files up into an archive and submit it to the Dioptra RESTful API to create a new job.\n",
    "For convenience, we provide the `make_tar` helper function defined in `examples/scripts/utils.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/c/users/jtsexton/documents/github/dioptra/examples/tensorflow-mnist-feature-squeezing/workflows.tar.gz')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_tar([\"src\"], WORKFLOWS_TAR_GZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect with the endpoint, we will use a client class defined in the `examples/scripts/client.py` file that is able to connect with the Dioptra RESTful API using the HTTP protocol.\n",
    "We connect using the client below.\n",
    "The client uses the environment variable `DIOPTRA_RESTAPI_URI`, which we configured at the top of the notebook, to figure out how to connect to the Dioptra RESTful API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "restapi_client = DioptraClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to register an experiment under which to collect our job runs.\n",
    "The code below checks if the relevant experiment named `\"mnist\"` exists.\n",
    "If it does, then it just returns info about the experiment, if it doesn't, it then registers the new experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lastModified': '2023-05-01T17:30:11.663914',\n",
       " 'createdOn': '2023-05-01T17:30:11.663914',\n",
       " 'experimentId': 2,\n",
       " 'name': 'jminiter_feature_squeezing'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_experiment = restapi_client.get_experiment_by_name(name=EXPERIMENT_NAME)\n",
    "\n",
    "if response_experiment is None or \"Not Found\" in response_experiment.get(\"message\", []):\n",
    "    response_experiment = restapi_client.register_experiment(name=EXPERIMENT_NAME)\n",
    "\n",
    "response_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to train our model.\n",
    "Depending on the specs of your computer, training either the shallow net model or the LeNet-5 model on a CPU can take 10-20 minutes or longer to complete.\n",
    "If you are fortunate enough to have access to a dedicated GPU, then the training time will be much shorter.\n",
    "\n",
    "So that we do not start this code by accident, we are embedding the code in a text block instead of keeping it in an executable code block.\n",
    "**If you need to train one of the models, create a new code block and copy and paste the code into it.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Submit training job for the shallow network architecture\n",
    "response_shallow_train = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"train\",\n",
    "    entry_point_kwargs=\" \".join([\n",
    "        \"-P model_architecture=shallow_net\",\n",
    "        \"-P epochs=30\",\n",
    "        \"-P register_model_name=mnist_shallow_net\",\n",
    "    ]),\n",
    "    queue=mlflow_queue,\n",
    ")\n",
    "\n",
    "print(\"Training job for shallow neural network submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_shallow_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Submit training job for the LeNet-5 network architecture\n",
    "response_le_net_train = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"train\",\n",
    "    entry_point_kwargs=\" \".join([\n",
    "        \"-P model_architecture=le_net\",\n",
    "        \"-P epochs=30\",\n",
    "        \"-P register_model_name=mnist_le_net\",\n",
    "    ]),\n",
    "    queue=mlflow_queue,\n",
    ")\n",
    "\n",
    "print(\"Training job for LeNet-5 neural network submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_le_net_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job for shallow neural network submitted\n",
      "\n",
      "{'createdOn': '2023-05-01T18:40:32.957998',\n",
      " 'dependsOn': None,\n",
      " 'entryPoint': 'train',\n",
      " 'entryPointKwargs': '-P model_architecture=shallow_net -P epochs=30 -P '\n",
      "                     'register_model_name=mnist_shallow_net -P '\n",
      "                     'data_dir=/dioptra/data/Mnist',\n",
      " 'experimentId': 2,\n",
      " 'jobId': '8aa0249f-d335-457a-83ca-3daa2873ca4b',\n",
      " 'lastModified': '2023-05-01T18:40:32.957998',\n",
      " 'mlflowRunId': None,\n",
      " 'queueId': 2,\n",
      " 'status': 'queued',\n",
      " 'timeout': '24h',\n",
      " 'workflowUri': 's3://workflow/2d225457d65b452192fde473aef3bd30/workflows.tar.gz'}\n",
      "Training job for LeNet-5 neural network submitted\n",
      "\n",
      "{'createdOn': '2023-05-01T18:40:33.109818',\n",
      " 'dependsOn': None,\n",
      " 'entryPoint': 'train',\n",
      " 'entryPointKwargs': '-P model_architecture=le_net -P epochs=30 -P '\n",
      "                     'register_model_name=mnist_le_net -P '\n",
      "                     'data_dir=/dioptra/data/Mnist',\n",
      " 'experimentId': 2,\n",
      " 'jobId': '56cb4d7b-74a1-49c2-802a-b14822158cab',\n",
      " 'lastModified': '2023-05-01T18:40:33.109818',\n",
      " 'mlflowRunId': None,\n",
      " 'queueId': 2,\n",
      " 'status': 'queued',\n",
      " 'timeout': '24h',\n",
      " 'workflowUri': 's3://workflow/814145537fd04d9ea778c21c4de82b77/workflows.tar.gz'}\n"
     ]
    }
   ],
   "source": [
    "response_shallow_train = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"train\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            \"-P model_architecture=shallow_net\",\n",
    "            \"-P epochs=30\",\n",
    "            \"-P register_model_name=mnist_shallow_net\",\n",
    "            f\"-P data_dir={mnist_dataset}\",\n",
    "        ]\n",
    "    ),\n",
    "    queue=mlflow_queue,\n",
    ")\n",
    "\n",
    "print(\"Training job for shallow neural network submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_shallow_train)\n",
    "\n",
    "# Submit training job for the LeNet-5 network architecture\n",
    "response_le_net_train = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"train\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            \"-P model_architecture=le_net\",\n",
    "            \"-P epochs=30\",\n",
    "            \"-P register_model_name=mnist_le_net\",\n",
    "            f\"-P data_dir={mnist_dataset}\",\n",
    "        ]\n",
    "    ),\n",
    "    queue=mlflow_queue,\n",
    ")\n",
    "\n",
    "print(\"Training job for LeNet-5 neural network submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_le_net_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'collection': 'dioptra_custom',\n",
       " 'status': 'Success',\n",
       " 'taskPluginName': ['feature_squeezing']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restapi_client.delete_custom_task_plugin(name = \"feature_squeezing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m╭─────────────────────────────────────────────────╮\u001b[0m\n",
      "\u001b[1;36m│\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36mDioptra Examples - Register Custom Task Plugins\u001b[0m\u001b[1;36m \u001b[0m\u001b[1;36m│\u001b[0m\n",
      "\u001b[1;36m╰─────────────────────────────────────────────────╯\u001b[0m\n",
      " ‣ \u001b[1mplugins_dir:\u001b[0m ..\u001b[35m/\u001b[0m\u001b[95mtask-plugins\u001b[0m\n",
      " ‣ \u001b[1mapi_url:\u001b[0m \u001b[4;39mhttp://localhost\u001b[0m\n",
      "\u001b[1;33mⒾ\u001b[0m  \u001b[1;37mSkipped.\u001b[0m \u001b[39mThe custom task plugin \u001b[0m\u001b[39m'evaluation'\u001b[0m\u001b[39m is already registered.\u001b[0m\n",
      " \u001b[1;92m✔\u001b[0m \u001b[1;32mSuccess!\u001b[0m \u001b[39mRegistered the custom task plugin \u001b[0m\u001b[39m'feature_squeezing'\u001b[0m\u001b[39m.\u001b[0m\n",
      " \u001b[1;92m✔\u001b[0m Custom task plugin registration is complete.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python ../scripts/register_task_plugins.py --plugins-dir ../task-plugins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block generates adversarial images on the MNIST dataset using the Fast Gradient Method attack and then attempts to classify the adversarial images.\n",
    "\n",
    "| parameter | type | description |\n",
    "| --- | --- | --- |\n",
    "| `eps` | _float_ | Attack step size. \\[default: 0.3\\] |\n",
    "| `eps_step` | _float_ | Step size of input variation for minimal perturbation computation. [default: 0.1] |\n",
    "| `targeted` | _bool_ | Indicates whether the attack is targeted (True) or untargeted (False). [default: False] |\n",
    "| `num_random_init` | _int_ | Number of random initializations within the epsilon ball. For ``random_init=0`` starting at the original input. [default: 0] |\n",
    "| `minimal` | _bool_ | Indicates if computing the minimal perturbation (True). If True, also define eps_step for the step size and eps for the maximum perturbation. [default: False] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGM attack job submitted\n",
      "\n",
      "{'createdOn': '2023-05-01T18:58:01.568696',\n",
      " 'dependsOn': None,\n",
      " 'entryPoint': 'fgm',\n",
      " 'entryPointKwargs': '-P model_name=mnist_le_net -P '\n",
      "                     'data_dir=/dioptra/data/Mnist -P model_version=5',\n",
      " 'experimentId': 2,\n",
      " 'jobId': 'edcf5b95-6412-4702-b5ff-2dc63d257ea5',\n",
      " 'lastModified': '2023-05-01T18:58:01.568696',\n",
      " 'mlflowRunId': None,\n",
      " 'queueId': 2,\n",
      " 'status': 'queued',\n",
      " 'timeout': '1m',\n",
      " 'workflowUri': 's3://workflow/cc58dc7387184dbb97e2d7b6afcdaa53/workflows.tar.gz'}\n",
      "\n",
      "Dependent jobs submitted\n"
     ]
    }
   ],
   "source": [
    "def mlflow_run_id_is_not_known(response_fgm):\n",
    "    return response_fgm[\"mlflowRunId\"] is None and response_fgm[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]\n",
    "\n",
    "response_fgm_le_net = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"fgm\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "            f\"-P data_dir={mnist_dataset}\",\n",
    "            f\"-P model_version={model_id}\"\n",
    "        ]\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "    timeout=\"1m\"\n",
    "\n",
    ")\n",
    "\n",
    "print(\"FGM attack job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_fgm_le_net)\n",
    "print(\"\")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_fgm_le_net):\n",
    "    time.sleep(1)\n",
    "    response_fgm_le_net = restapi_client.get_job_by_id(response_fgm_le_net[\"jobId\"]) \n",
    "    \n",
    "response_infer = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_fgm_le_net['mlflowRunId']}\",\n",
    "            f\"-P model_version={model_id}\",\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "        ]\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "    depends_on=response_fgm_le_net[\"jobId\"]\n",
    ")\n",
    "    \n",
    "print(\"Dependent jobs submitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block does the same as the previous block, but applies the feature squeezing defense between the attack and infer steps.\n",
    "This pre-processing defense compresses the images being classified by our neural network such that their color depth is reduced to a binary, monochrome pallete.\n",
    "The level of compression can be tuned by adjusting the bit_depth parameter below (use values between 1 (binary) and 8 (original image color depth) to tune the defense.\n",
    "\n",
    "**FGM parameters**\n",
    "\n",
    "| parameter | type | description |\n",
    "| --- | --- | --- |\n",
    "| `eps` | _float_ | Attack step size. \\[default: 0.3\\] |\n",
    "| `eps_step` | _float_ | Step size of input variation for minimal perturbation computation. [default: 0.1] |\n",
    "| `targeted` | _bool_ | Indicates whether the attack is targeted (True) or untargeted (False). [default: False] |\n",
    "| `num_random_init` | _int_ | Number of random initializations within the epsilon ball. For ``random_init=0`` starting at the original input. [default: 0] |\n",
    "| `minimal` | _bool_ | Indicates if computing the minimal perturbation (True). If True, also define eps_step for the step size and eps for the maximum perturbation. [default: False] |\n",
    "\n",
    "**Feature squeezing parameters**\n",
    "\n",
    "| parameter | type | description |\n",
    "| --- | --- | --- |\n",
    "| `bit_depth` | _int_ | An integer between 1-8 that defines the color depth of the squeezed image. [default: 8] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGM attack  job submitted\n",
      "\n",
      "{'createdOn': '2023-05-02T15:43:53.677153',\n",
      " 'dependsOn': None,\n",
      " 'entryPoint': 'fgm',\n",
      " 'entryPointKwargs': '-P model_name=mnist_le_net -P '\n",
      "                     'data_dir=/dioptra/data/Mnist -P model_version=5',\n",
      " 'experimentId': 2,\n",
      " 'jobId': '54f4f35b-2893-4396-8b7a-4aad671fbb11',\n",
      " 'lastModified': '2023-05-02T15:43:53.677153',\n",
      " 'mlflowRunId': None,\n",
      " 'queueId': 2,\n",
      " 'status': 'queued',\n",
      " 'timeout': '24h',\n",
      " 'workflowUri': 's3://workflow/d03615c553304117adf01b2956c860fa/workflows.tar.gz'}\n",
      "\n",
      "{'experimentId': 2, 'entryPoint': 'fgm', 'createdOn': '2023-05-02T15:43:53.677153', 'mlflowRunId': 'd7ef0a1331384dc597b53d997f349e41', 'workflowUri': 's3://workflow/d03615c553304117adf01b2956c860fa/workflows.tar.gz', 'lastModified': '2023-05-02T15:44:20.748660', 'dependsOn': None, 'status': 'queued', 'timeout': '24h', 'entryPointKwargs': '-P model_name=mnist_le_net -P data_dir=/dioptra/data/Mnist -P model_version=5', 'jobId': '54f4f35b-2893-4396-8b7a-4aad671fbb11', 'queueId': 2}\n",
      "{'experimentId': 2, 'entryPoint': 'feature_squeeze', 'createdOn': '2023-05-02T15:44:20.929451', 'mlflowRunId': 'bdc70372ba50447b955d22990719f0cc', 'workflowUri': 's3://workflow/e61f7c27979b4ce0bfdd458060d4e1f9/workflows.tar.gz', 'lastModified': '2023-05-02T15:45:13.629988', 'dependsOn': '54f4f35b-2893-4396-8b7a-4aad671fbb11', 'status': 'started', 'timeout': '1h', 'entryPointKwargs': '-P run_id=d7ef0a1331384dc597b53d997f349e41 -P model=mnist_le_net/5 -P model_architecture=le_net -P bit_depth=1 -P batch_size=32', 'jobId': 'c2df3d18-c72c-4585-893c-2c49fd2733ac', 'queueId': 2}\n",
      "Dependent jobs submitted\n"
     ]
    }
   ],
   "source": [
    "def mlflow_run_id_is_not_known(response_fgm):\n",
    "    return response_fgm[\"mlflowRunId\"] is None and response_fgm[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]\n",
    "\n",
    "response_fgm_le_net = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"fgm\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "            f\"-P data_dir={mnist_dataset}\",\n",
    "            f\"-P model_version={model_id}\"\n",
    "        ]\n",
    "\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "\n",
    ")\n",
    "\n",
    "print(\"FGM attack  job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_fgm_le_net)\n",
    "print(\"\")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_fgm_le_net):\n",
    "    time.sleep(1)\n",
    "    response_fgm_le_net = restapi_client.get_job_by_id(response_fgm_le_net[\"jobId\"])\n",
    "print(response_fgm_le_net)\n",
    "\n",
    "response_feature_squeeze = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"feature_squeeze\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_fgm_le_net['mlflowRunId']}\",\n",
    "            f\"-P model={mnist_model}/{model_id}\",\n",
    "            \"-P model_architecture=le_net\",\n",
    "            \"-P bit_depth=1\",\n",
    "            \"-P batch_size=32\"\n",
    "        ]\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "    depends_on=response_fgm_le_net[\"jobId\"],\n",
    "    timeout = \"1h\"\n",
    ")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_feature_squeeze):\n",
    "    time.sleep(1)\n",
    "    response_feature_squeeze = restapi_client.get_job_by_id(response_feature_squeeze[\"jobId\"]) \n",
    "print(response_feature_squeeze)\n",
    "response_infer_defended = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_feature_squeeze['mlflowRunId']}\",\n",
    "            f\"-P model_version={model_id}\",\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "        ]\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "    depends_on=response_feature_squeeze[\"jobId\"]\n",
    ")\n",
    "    \n",
    "print(\"Dependent jobs submitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block uses the carlini-wagner attack with the Linf distance metric to generate adversarial images and checks the model's accuracy against the attack.\n",
    "\n",
    "**Carlini Wagner Parameters**\n",
    "\n",
    "| parameter | type | description |\n",
    "| --- | --- | --- |\n",
    "| `targeted` | _bool_ | Indicates whether the attack is targeted (True) or untargeted (False). [default: False] |\n",
    "| `learning_rate` | _float_ | The initial learning rate for the attack algorithm. Smaller values produce better results but are slower to converge. [default: 0.01] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carlini Wagner attack job submitted\n",
      "\n",
      "{'createdOn': '2023-05-02T16:45:24.933323',\n",
      " 'dependsOn': None,\n",
      " 'entryPoint': 'cw_inf',\n",
      " 'entryPointKwargs': '-P model_name=mnist_shallow_net -P model_version=3 -P '\n",
      "                     'model_architecture=shallow_net -P targeted=True -P '\n",
      "                     'max_iter=10 -P confidence=0.0 -P '\n",
      "                     'data_dir=/dioptra/data/Mnist -P learning_rate=0.01 -P '\n",
      "                     'verbose=True -P batch_size=32',\n",
      " 'experimentId': 2,\n",
      " 'jobId': '751b009c-c25c-414b-bfe9-8bc7991420d9',\n",
      " 'lastModified': '2023-05-02T16:45:24.933323',\n",
      " 'mlflowRunId': None,\n",
      " 'queueId': 2,\n",
      " 'status': 'queued',\n",
      " 'timeout': '24h',\n",
      " 'workflowUri': 's3://workflow/473dcd7321d04b5888ff6a63a6f27df1/workflows.tar.gz'}\n",
      "\n",
      "Dependent jobs submitted\n"
     ]
    }
   ],
   "source": [
    "def mlflow_run_id_is_not_known(response_fgm):\n",
    "    return response_fgm[\"mlflowRunId\"] is None and response_fgm[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]\n",
    "\n",
    "response_fgm_le_net = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"cw_inf\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P model_name={mnist_shallow}\",\n",
    "            f\"-P model_version={model_id_shallow}\",\n",
    "            \"-P model_architecture=shallow_net\",\n",
    "            \"-P targeted=True\",\n",
    "            \"-P max_iter=10\",\n",
    "            \"-P confidence=0.0\",\n",
    "            f\"-P data_dir={mnist_dataset}\",\n",
    "            \"-P learning_rate=0.01\",\n",
    "            \"-P verbose=True\",\n",
    "            \"-P batch_size=32\"\n",
    "        ]\n",
    "\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "\n",
    ")\n",
    "\n",
    "print(\"Carlini Wagner attack job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_fgm_le_net)\n",
    "print(\"\")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_fgm_le_net):\n",
    "    time.sleep(1)\n",
    "    response_fgm_le_net = restapi_client.get_job_by_id(response_fgm_le_net[\"jobId\"])\n",
    "\n",
    "response_le_net_infer_le_net_fgm = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "         [\n",
    "             f\"-P run_id={response_fgm_le_net['mlflowRunId']}\",\n",
    "             f\"-P model_version={model_id_shallow}\",\n",
    "             f\"-P model_name={mnist_shallow}\",\n",
    "        ]\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "    depends_on=response_fgm_le_net[\"jobId\"],\n",
    ")\n",
    "\n",
    "print(\"Dependent jobs submitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block does the same as the previous block, but applies the feature squeezing defense between the attack and infer steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carlini Wagner attack job submitted\n",
      "\n",
      "{'createdOn': '2023-05-02T18:31:15.296745',\n",
      " 'dependsOn': None,\n",
      " 'entryPoint': 'cw_inf',\n",
      " 'entryPointKwargs': '-P model_name=mnist_shallow_net -P model_version=3 -P '\n",
      "                     'model_architecture=shallow_net -P targeted=True -P '\n",
      "                     'max_iter=20 -P confidence=0.0 -P '\n",
      "                     'data_dir=/dioptra/data/Mnist -P learning_rate=0.01 -P '\n",
      "                     'verbose=True -P batch_size=32',\n",
      " 'experimentId': 2,\n",
      " 'jobId': '076dd10a-a195-46ae-b7bb-812c7f23f901',\n",
      " 'lastModified': '2023-05-02T18:31:15.296745',\n",
      " 'mlflowRunId': None,\n",
      " 'queueId': 2,\n",
      " 'status': 'queued',\n",
      " 'timeout': '24h',\n",
      " 'workflowUri': 's3://workflow/db13160548664e17ac946c8f53a01b4a/workflows.tar.gz'}\n",
      "\n",
      "Dependent jobs submitted\n"
     ]
    }
   ],
   "source": [
    "def mlflow_run_id_is_not_known(response_fgm):\n",
    "    return response_fgm[\"mlflowRunId\"] is None and response_fgm[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]\n",
    "\n",
    "response_fgm_le_net = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"cw_inf\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P model_name={mnist_shallow}\", \n",
    "            f\"-P model_version={model_id_shallow}\", \n",
    "            \"-P model_architecture=shallow_net\",\n",
    "            \"-P targeted=True\", \n",
    "            \"-P max_iter=20\",\n",
    "            \"-P confidence=0.0\", \n",
    "            f\"-P data_dir={mnist_dataset}\", \n",
    "            \"-P learning_rate=0.01\", \n",
    "            \"-P verbose=True\", \n",
    "            \"-P batch_size=32\"\n",
    "        ]\n",
    "\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print(\"Carlini Wagner attack job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_fgm_le_net)\n",
    "print(\"\")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_fgm_le_net):\n",
    "    time.sleep(1)\n",
    "    response_fgm_le_net = restapi_client.get_job_by_id(response_fgm_le_net[\"jobId\"])\n",
    "\n",
    "response_feature_squeeze = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"feature_squeeze\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_fgm_le_net['mlflowRunId']}\",\n",
    "            f\"-P model={mnist_shallow}/{model_id_shallow}\",\n",
    "            \"-P model_architecture=shallow_net\",\n",
    "            \"-P bit_depth=1\",\n",
    "            \"-P batch_size=32\"\n",
    "        ]\n",
    "    ),\n",
    "    depends_on=response_fgm_le_net[\"jobId\"],\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_feature_squeeze):\n",
    "    time.sleep(1)\n",
    "    response_feature_squeeze = restapi_client.get_job_by_id(response_fgm_le_net[\"jobId\"])\n",
    "\n",
    "response_le_net_infer_le_net_fgm = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_feature_squeeze['mlflowRunId']}\",\n",
    "            f\"-P model_name={mnist_shallow}\",\n",
    "            f\"-P model_version={model_id_shallow}\"\n",
    "        ]\n",
    "    ),\n",
    "    depends_on=response_feature_squeeze[\"jobId\"],\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print(\"Dependent jobs submitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block uses the carlini-wagner attack using the L2 distance metric to generate adversarial images and checks the model's accuracy against the attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carlini Wagner attack job submitted\n",
      "\n",
      "{'createdOn': '2023-05-02T18:46:14.839536',\n",
      " 'dependsOn': None,\n",
      " 'entryPoint': 'cw_l2',\n",
      " 'entryPointKwargs': '-P model_name=mnist_shallow_net -P model_version=3 -P '\n",
      "                     'binary_search_steps=50 -P initial_const=0.01 -P '\n",
      "                     'model_architecture=shallow_net -P max_iter=10 -P '\n",
      "                     'data_dir=/dioptra/data/Mnist -P verbose=True -P '\n",
      "                     'batch_size=32',\n",
      " 'experimentId': 2,\n",
      " 'jobId': 'f723253d-a578-49da-ad57-80a835848c1d',\n",
      " 'lastModified': '2023-05-02T18:46:14.839536',\n",
      " 'mlflowRunId': None,\n",
      " 'queueId': 2,\n",
      " 'status': 'queued',\n",
      " 'timeout': '24h',\n",
      " 'workflowUri': 's3://workflow/c5b1a6fafb414487a91c3c4fa6ff94cb/workflows.tar.gz'}\n",
      "\n",
      "Dependent jobs submitted\n"
     ]
    }
   ],
   "source": [
    "def mlflow_run_id_is_not_known(response_fgm):\n",
    "    return response_fgm[\"mlflowRunId\"] is None and response_fgm[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]\n",
    "\n",
    "response_fgm_le_net = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"cw_l2\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P model_name={mnist_shallow}\",\n",
    "            f\"-P model_version={model_id_shallow}\",\n",
    "            \"-P binary_search_steps=50\", \n",
    "            \"-P initial_const=0.01\",\n",
    "            \"-P model_architecture=shallow_net\",\n",
    "            \"-P max_iter=10\",\n",
    "            f\"-P data_dir={mnist_dataset}\",\n",
    "            \"-P verbose=True\",\n",
    "            \"-P batch_size=32\"]\n",
    "\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "\n",
    ")\n",
    "\n",
    "print(\"Carlini Wagner attack job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_fgm_le_net)\n",
    "print(\"\")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_fgm_le_net):\n",
    "    time.sleep(1)\n",
    "    response_fgm_le_net = restapi_client.get_job_by_id(response_fgm_le_net[\"jobId\"])\n",
    "\n",
    "response_le_net_infer_le_net_fgm = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_fgm_le_net['mlflowRunId']}\",\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "            f\"-P model_version={model_id}\",\n",
    "        ]\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "\n",
    "    depends_on=response_fgm_le_net[\"jobId\"],\n",
    ")\n",
    "\n",
    "print(\"Dependent jobs submitted\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block uses the Deepfool attack to generate adversarial MNIST images, applies the feature squeezing defense, and checks the model's accuracy against the defended adversarial dataset.\n",
    "\n",
    "**Unique Deepfool parameters**\n",
    "\n",
    "| parameter | type | description |\n",
    "| --- | --- | --- |\n",
    "| `epsilon` | _float_ | Overshoot parameter. [default: 0.00001] |\n",
    "| `nb_grads` | _int_ | Number of class gradients to compute. [default: 10] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_run_id_is_not_known(response_fgm):\n",
    "    return response_fgm[\"mlflowRunId\"] is None and response_fgm[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]\n",
    "\n",
    "response_fgm_le_net = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"deepfool\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "            f\"-P data_dir={mnist_dataset}/training\",\n",
    "            \"-P model_architecture=le_net\",\n",
    "            \"-P batch_size=32\",\n",
    "            \"-P max_iter=10\",\n",
    "            \"-P verbose=True\",\n",
    "            \"-P nb_grads=10\",\n",
    "            \"-P epsilon=0.000001\",\n",
    "        ],\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print(\"Deepfool attack (Mobilenet architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_fgm_le_net)\n",
    "print(\"\")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_fgm_le_net):\n",
    "    time.sleep(1)\n",
    "    response_fgm_le_net = restapi_client.get_job_by_id(response_fgm_le_net[\"jobId\"])\n",
    "\n",
    "response_feature_squeeze = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"feature_squeeze\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_fgm_le_net['mlflowRunId']}\",\n",
    "            f\"-P model={mnist_model}/{model_id}\",\n",
    "            \"-P model_architecture=le_net\",\n",
    "            \"-P bit_depth=1\",\n",
    "            \"-P batch_size=32\",\n",
    "            f\"-P data_dir={mnist_dataset}/training\",\n",
    "        ],\n",
    "    ),\n",
    "    depends_on=response_fgm_le_net[\"jobId\"],\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_feature_squeeze):\n",
    "    time.sleep(1)\n",
    "    response_feature_squeeze = restapi_client.get_job_by_id(response_feature_squeeze[\"jobId\"])\n",
    "\n",
    "response_le_net_infer_le_net_fgm = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_feature_squeeze['mlflowRunId']}\",\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "            \"-P batch_size=32\"\n",
    "        ],\n",
    "    ),\n",
    "    depends_on=response_feature_squeeze[\"jobId\"],\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print(\"Dependent jobs submitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block does the same as the previous block, but applies the feature squeezing defense between the attack and infer steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_run_id_is_not_known(response_fgm):\n",
    "    return response_fgm[\"mlflowRunId\"] is None and response_fgm[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]\n",
    "\n",
    "response_fgm_le_net = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"deepfool\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "            f\"-P data_dir={mnist_dataset}/training\",\n",
    "            \"-P model_architecture=le_net\",\n",
    "            \"-P batch_size=32\",\n",
    "            \"-P max_iter=10\",\n",
    "            \"-P verbose=True\",\n",
    "            \"-P nb_grads=10\",\n",
    "            \"-P epsilon=0.000001\",\n",
    "            \"-P image_size=28,28\"\n",
    "        ],\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print(\"Deepfool attack (Mobilenet architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_fgm_le_net)\n",
    "print(\"\")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_fgm_le_net):\n",
    "    time.sleep(1)\n",
    "    response_fgm_le_net = restapi_client.get_job_by_id(response_fgm_le_net[\"jobId\"])\n",
    "\n",
    "response_le_net_infer_le_net_fgm = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_fgm_le_net['mlflowRunId']}\",\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "            \"-P batch_size=32\",\n",
    "        ]\n",
    "    ),\n",
    "    depends_on=response_fgm_le_net[\"jobId\"],\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print(\"Dependent jobs submitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block applies the Jacobian Saliency Map Approach attack to generate adversarial images for the MNIST dataset.\n",
    "\n",
    "**Unique JSMA parameters**\n",
    "\n",
    "| parameter | type | description |\n",
    "| --- | --- | --- |\n",
    "| `theta` | _float_ | Amount of Perturbation introduced to each modified feature per step (can be positive or negative). [default: 0.1] |\n",
    "| `gamma` | _float_ | Maximum fraction of features being perturbed (between 0 and 1). [default: 1.0] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mlflow_run_id_is_not_known(response_fgm):\n",
    "    return response_fgm[\"mlflowRunId\"] is None and response_fgm[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]\n",
    "\n",
    "response_jsma = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"jsma\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "            f\"-P model_version={model_id}\", \n",
    "            \"-P model_architecture=le_net\", \n",
    "            \"-P theta=4.5\",\n",
    "            \"-P verbose=True\",\n",
    "            \"-P gamma=1.0\", \n",
    "            f\"-P data_dir={mnist_dataset}\"\n",
    "        ] \n",
    "\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "\n",
    ")\n",
    "\n",
    "print(\"JSMA attack (LeNet-5 architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_jsma)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_jsma):\n",
    "    time.sleep(1)\n",
    "    response_jsma = restapi_client.get_job_by_id(response_jsma[\"jobId\"])\n",
    "\n",
    "response_le_net_infer_le_net_fgm = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_jsma['mlflowRunId']}\",\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "            f\"-P model_version={model_id}\",\n",
    "        ]\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "    depends_on=response_jsma[\"jobId\"],\n",
    ")\n",
    "\n",
    "print(\"Dependent jobs submitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block does the same as the previous block, but applies the feature squeezing defense between the attack and infer steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_run_id_is_not_known(response_fgm):\n",
    "    return response_fgm[\"mlflowRunId\"] is None and response_fgm[\"status\"] not in [\n",
    "        \"failed\",\n",
    "        \"finished\",\n",
    "    ]\n",
    "\n",
    "response_jsma = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"jsma\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "            f\"-P model_version={model_id}\", \n",
    "            \"-P model_architecture=le_net\", \n",
    "            \"-P theta=4.5\",\n",
    "            \"-P verbose=True\",\n",
    "            \"-P gamma=1.0\", \n",
    "            f\"-P data_dir={mnist_dataset}\"\n",
    "        ] \n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    ")\n",
    "\n",
    "print(\"JSMA attack (LeNet-5 architecture) job submitted\")\n",
    "print(\"\")\n",
    "pprint.pprint(response_jsma)\n",
    "print(\"\")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_jsma):\n",
    "    time.sleep(1)\n",
    "    response_jsma = restapi_client.get_job_by_id(response_jsma[\"jobId\"])\n",
    "\n",
    "response_feature_squeeze = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"feature_squeeze\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_jsma['mlflowRunId']}\",\n",
    "            f\"-P model={mnist_model}/{model_id}\",\n",
    "            \"-P model_architecture=le_net\",\n",
    "            \"-P bit_depth=1\",\n",
    "            \"-P batch_size=32\"\n",
    "        ]\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "    depends_on=response_jsma[\"jobId\"],\n",
    ")\n",
    "\n",
    "while mlflow_run_id_is_not_known(response_feature_squeeze):\n",
    "    time.sleep(1)\n",
    "    response_feature_squeeze = restapi_client.get_job_by_id(response_feature_squeeze[\"jobId\"])\n",
    "\n",
    "response_le_net_infer_le_net_jsma = restapi_client.submit_job(\n",
    "    workflows_file=WORKFLOWS_TAR_GZ,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    entry_point=\"infer\",\n",
    "    entry_point_kwargs=\" \".join(\n",
    "        [\n",
    "            f\"-P run_id={response_jsma['mlflowRunId']}\",\n",
    "            f\"-P model_name={mnist_model}\",\n",
    "            f\"-P model_version={model_id}\",\n",
    "        ]\n",
    "    ),\n",
    "    queue = mlflow_queue,\n",
    "    depends_on=response_feature_squeeze[\"jobId\"],\n",
    ")\n",
    "\n",
    "print(\"Dependent jobs submitted\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edee40310913f16e2ca02c1d37887bcb7f07f00399ca119bb7e27de7d632ea99"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
